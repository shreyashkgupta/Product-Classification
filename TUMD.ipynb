{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMo Vectorization for Banned Products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating ELMo vectors for total unique modelling dataset and then creating different models to classsify products as rejected or approved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Shreyash Gupta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organization: IndiaMART InterMESH Pvt. Ltd."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumd = pd.read_csv(\"totaluniquemodeldata.txt\", names = [\"Product\",\"Label\"], engine = \"python\", error_bad_lines = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating table format from txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumd['Label'] = [tumd.values[i][0].split()[0].replace(\"__label__\",\"\",1) for i in range(tumd.shape[0])]\n",
    "tumd['Product'] = [tumd.values[i][0].replace(tumd.values[i][0].split()[0] + \" \",\"\") for i in range(tumd.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the label distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumd['Label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Remove special symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_symbols = '!@#$%^&*()_-+=[]\\{}|;\",.<>/?~:\\\"'\n",
    "tumd['cleanProduct'] = tumd['Product'].apply(lambda rss: ''.join(ch for ch in rss if ch not in set(special_symbols)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Convert all characters to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumd['cleanProduct'] = tumd['cleanProduct'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Remove white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumd['cleanProduct'] = tumd['cleanProduct'].apply(lambda rws: ' '.join(rws.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing differences before/after preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tumd.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing ELMo vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the ELMo module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining function for creating ELMo vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elmo_vectors(text):\n",
    "    embeddings = elmo(text.tolist(),signature = \"default\", as_dict = True)[\"elmo\"]\n",
    "    with tf.compat.v1.Session() as session:\n",
    "        session.run(tf.compat.v1.global_variables_initializer())\n",
    "        session.run(tf.compat.v1.tables_initializer())\n",
    "        return session.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting dataset into batches for better computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_start_time = time.time()\n",
    "tumd_list = [tumd[i:i+100] for i in range(0,tumd.shape[0],100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting ELMo vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_extraction_start_time = time.time()\n",
    "tumd_elmo_train = [elmo_vectors(x['cleanProduct']) for x in tumd_list]\n",
    "elmo_extraction_end_time = time.time()\n",
    "print(\"Total extraction time for ELMo vectors: {} seconds\".format(elmo_extraction_end_time - elmo_extraction_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenatening all batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_concat_start_time = time.time()\n",
    "elmo_tumd_train = np.concatenate(tumd_elmo_train, axis = 0)\n",
    "elmo_end_time = elmo_concat_end_time = time.time()\n",
    "print(\"Total concatenation time: {} seconds\".format(elmo_concat_end_time - elmo_concat_start_time))\n",
    "print(\"Total time for ELMo vector extraction: {} seconds\".format(elmo_end_time - elmo_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving output to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"tumd_train_05062019.pickle\",\"wb\")\n",
    "pickle.dump(tumd_faq_train, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading ELMo vectors pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"tumd_train_03062019.pickle\",\"rb\")\n",
    "tumd_faq_train = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building different models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(tumd_faq_train,tumd['Label'],random_state = 42, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buidling a logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_start_time = time.time()\n",
    "regressor = LogisticRegression()\n",
    "regressor.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_lr = regressor.predict(xvalid)\n",
    "lr_end_time = time.time()\n",
    "print(\"Total time spent on LR: {} seconds\".format(lr_end_time - lr_start_time))\n",
    "print(\"Individual time for LR inclusive of ELMo extraction: {} seconds\".format(lr_end_time - elmo_start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Logistic Regression\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_lr,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_lr,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_lr,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_start_time = time.time()\n",
    "nbclassifier = GaussianNB()\n",
    "nbclassifier.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_nb = nbclassifier.predict(xvalid)\n",
    "nb_end_time = time.time()\n",
    "print(\"Total time spent on NB: {} seconds\".format(nb_end_time - nb_start_time))\n",
    "print(\"Individual time for NB inclusive of ELMo extraction: {} seconds\".format(nb_end_time - elmo_start_time - (nb_start_time - lr_start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Naive Bayes\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_nb,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_nb,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_nb,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a Linear SVM (SGD) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_start_time = time.time()\n",
    "sgdclassifier = SGDClassifier()\n",
    "sgdclassifier.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_val_sgd = sgdclassifier.predict(xvalid)\n",
    "sgd_end_time = time.time()\n",
    "print(\"Total time spent on SVM (SGD): {} seconds\".format(sgd_end_time - sgd_start_time))\n",
    "print(\"Individual time for SVM (SGD) inclusive of ELMo extraction: {} seconds\".format(sgd_end_time - elmo_start_time - (sgd_start_time - lr_start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of Linear SVM (SGD) Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Linear SVM (SGD)\")\n",
    "print(\"Precision: \",precision_score(yvalid,pred_val_sgd,pos_label='FAQ'))\n",
    "print(\"Recall: \",recall_score(yvalid,pred_val_sgd,pos_label='FAQ'))\n",
    "print(\"F1 Score: \",f1_score(yvalid, pred_val_sgd,pos_label='FAQ'))\n",
    "print(\"MCC: \",matthews_corrcoef(yvalid, pred_val_sgd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
